{"ast":null,"code":"var _jsxFileName = \"/Users/stephaniecheney/Development/code/Mod5FinalProject/my-project-client/src/Voice.js\";\nimport React from 'react';\nimport { connect } from 'react-redux';\n\nfunction Voice() {\n  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n  const recognition = new SpeechRecognition();\n\n  recognition.onstart = function () {\n    console.log(\"voice is activated, you can speak into microphone\");\n  };\n\n  recognition.onresult = function (event) {\n    const current = event.resultIndex;\n    const transcript = event.results[current][0].transcript;\n    const transcriptOutput = document.getElementById(\"transcript\");\n    transcriptOutput.textContent = transcript.upcase();\n\n    if (transcript === \"hello\") {\n      const transcriptTitle = document.getElementById(\"correct\");\n      transcriptTitle.textContent = \"CORRECT!\";\n    }\n  };\n\n  return /*#__PURE__*/React.createElement(\"div\", {\n    class: \"voice-bg-img\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 30,\n      columnNumber: 13\n    }\n  }, /*#__PURE__*/React.createElement(\"button\", {\n    onClick: () => {\n      recognition.start();\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 31,\n      columnNumber: 17\n    }\n  }, \"Respond\"), /*#__PURE__*/React.createElement(\"h3\", {\n    id: \"transcript\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 32,\n      columnNumber: 17\n    }\n  }), /*#__PURE__*/React.createElement(\"h1\", {\n    id: \"correct\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 33,\n      columnNumber: 17\n    }\n  }));\n}\n\nconst mapStateToProps = state => ({\n  users: state.users\n});\n\nexport default connect(mapStateToProps)(Voice);","map":{"version":3,"sources":["/Users/stephaniecheney/Development/code/Mod5FinalProject/my-project-client/src/Voice.js"],"names":["React","connect","Voice","SpeechRecognition","window","webkitSpeechRecognition","recognition","onstart","console","log","onresult","event","current","resultIndex","transcript","results","transcriptOutput","document","getElementById","textContent","upcase","transcriptTitle","start","mapStateToProps","state","users"],"mappings":";AAAA,OAAOA,KAAP,MAAkB,OAAlB;AACA,SAAQC,OAAR,QAAsB,aAAtB;;AAGA,SAASC,KAAT,GAAiB;AACb,QAAMC,iBAAiB,GACvBC,MAAM,CAACD,iBAAP,IAA4BC,MAAM,CAACC,uBADnC;AAGA,QAAMC,WAAW,GAAE,IAAIH,iBAAJ,EAAnB;;AAEAG,EAAAA,WAAW,CAACC,OAAZ,GAAoB,YAAU;AAC1BC,IAAAA,OAAO,CAACC,GAAR,CAAY,mDAAZ;AACH,GAFD;;AAIAH,EAAAA,WAAW,CAACI,QAAZ,GAAqB,UAASC,KAAT,EAAe;AAChC,UAAMC,OAAO,GAAGD,KAAK,CAACE,WAAtB;AAEA,UAAMC,UAAU,GAAEH,KAAK,CAACI,OAAN,CAAcH,OAAd,EAAuB,CAAvB,EAA0BE,UAA5C;AACA,UAAME,gBAAgB,GAACC,QAAQ,CAACC,cAAT,CAAwB,YAAxB,CAAvB;AACAF,IAAAA,gBAAgB,CAACG,WAAjB,GAA6BL,UAAU,CAACM,MAAX,EAA7B;;AAEA,QAAGN,UAAU,KAAG,OAAhB,EAAwB;AACpB,YAAMO,eAAe,GAACJ,QAAQ,CAACC,cAAT,CAAwB,SAAxB,CAAtB;AACAG,MAAAA,eAAe,CAACF,WAAhB,GAA4B,UAA5B;AACH;AACJ,GAXD;;AAcA,sBACQ;AAAK,IAAA,KAAK,EAAC,cAAX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACI;AAAQ,IAAA,OAAO,EAAE,MAAI;AAACb,MAAAA,WAAW,CAACgB,KAAZ;AAAoB,KAA1C;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,eADJ,eAEI;AAAI,IAAA,EAAE,EAAC,YAAP;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAFJ,eAGI;AAAI,IAAA,EAAE,EAAC,SAAP;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAHJ,CADR;AAQH;;AAED,MAAMC,eAAe,GAACC,KAAK,KAAG;AAC1BC,EAAAA,KAAK,EAAED,KAAK,CAACC;AADa,CAAH,CAA3B;;AAGA,eAAexB,OAAO,CAACsB,eAAD,CAAP,CAAyBrB,KAAzB,CAAf","sourcesContent":["import React from 'react';\nimport {connect} from 'react-redux'\n\n\nfunction Voice() {\n    const SpeechRecognition=\n    window.SpeechRecognition || window.webkitSpeechRecognition;\n\n    const recognition= new SpeechRecognition();\n\n    recognition.onstart=function(){\n        console.log(\"voice is activated, you can speak into microphone\");\n    }\n\n    recognition.onresult=function(event){\n        const current = event.resultIndex;\n\n        const transcript= event.results[current][0].transcript;\n        const transcriptOutput=document.getElementById(\"transcript\")\n        transcriptOutput.textContent=transcript.upcase() \n\n        if(transcript===\"hello\"){\n            const transcriptTitle=document.getElementById(\"correct\")\n            transcriptTitle.textContent=\"CORRECT!\"\n        }\n    }\n\n\n    return(\n            <div class=\"voice-bg-img\">\n                <button onClick={()=>{recognition.start()}}>Respond</button>\n                <h3 id=\"transcript\"></h3>\n                <h1 id=\"correct\"></h1>\n            </div>\n            \n    )\n}\n\nconst mapStateToProps=state=>({\n    users: state.users\n})\nexport default connect(mapStateToProps)(Voice)\n\n\n"]},"metadata":{},"sourceType":"module"}