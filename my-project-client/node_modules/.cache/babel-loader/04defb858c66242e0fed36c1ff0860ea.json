{"ast":null,"code":"var _jsxFileName = \"/Users/stephaniecheney/Development/code/Mod5FinalProject/my-project-client/src/voiceLevel.js\";\nimport React from 'react';\n\nfunction voiceLevel() {\n  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n  const recognition = new SpeechRecognition();\n\n  recognition.onstart = function () {\n    console.log(\"voice is activated, you can speak into microphone\");\n  };\n\n  recognition.onresult = function (event) {\n    const current = event.resultIndex;\n    const transcript = event.results[current][0].transcript;\n    console.log(transcript);\n  };\n\n  return /*#__PURE__*/React.createElement(\"button\", {\n    onClick: () => {\n      recognition.start();\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 23,\n      columnNumber: 13\n    }\n  }, \"Talk\");\n}\n\nexport default voiceLevel;","map":{"version":3,"sources":["/Users/stephaniecheney/Development/code/Mod5FinalProject/my-project-client/src/voiceLevel.js"],"names":["React","voiceLevel","SpeechRecognition","window","webkitSpeechRecognition","recognition","onstart","console","log","onresult","event","current","resultIndex","transcript","results","start"],"mappings":";AAAA,OAAOA,KAAP,MAAkB,OAAlB;;AAGA,SAASC,UAAT,GAAsB;AAClB,QAAMC,iBAAiB,GACvBC,MAAM,CAACD,iBAAP,IAA4BC,MAAM,CAACC,uBADnC;AAGA,QAAMC,WAAW,GAAE,IAAIH,iBAAJ,EAAnB;;AAEAG,EAAAA,WAAW,CAACC,OAAZ,GAAoB,YAAU;AAC1BC,IAAAA,OAAO,CAACC,GAAR,CAAY,mDAAZ;AACH,GAFD;;AAIAH,EAAAA,WAAW,CAACI,QAAZ,GAAqB,UAASC,KAAT,EAAe;AAChC,UAAMC,OAAO,GAAGD,KAAK,CAACE,WAAtB;AAEA,UAAMC,UAAU,GAAEH,KAAK,CAACI,OAAN,CAAcH,OAAd,EAAuB,CAAvB,EAA0BE,UAA5C;AACAN,IAAAA,OAAO,CAACC,GAAR,CAAYK,UAAZ;AACH,GALD;;AAQA,sBACQ;AAAQ,IAAA,OAAO,EAAE,MAAI;AAACR,MAAAA,WAAW,CAACU,KAAZ;AAAoB,KAA1C;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YADR;AAGH;;AAED,eAAed,UAAf","sourcesContent":["import React from 'react';\n\n\nfunction voiceLevel() {\n    const SpeechRecognition=\n    window.SpeechRecognition || window.webkitSpeechRecognition;\n\n    const recognition= new SpeechRecognition();\n\n    recognition.onstart=function(){\n        console.log(\"voice is activated, you can speak into microphone\");\n    }\n\n    recognition.onresult=function(event){\n        const current = event.resultIndex;\n\n        const transcript= event.results[current][0].transcript;\n        console.log(transcript)\n    }\n\n\n    return(\n            <button onClick={()=>{recognition.start()}}>Talk</button>\n    )\n}\n\nexport default voiceLevel;\n\n\n"]},"metadata":{},"sourceType":"module"}